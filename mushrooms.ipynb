{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I used a Decision Tree Classifier to determine the most important features in predicting whether a mushroom is poisonous. This dataset has over 8000 instances and 22 attributes relating to visual, olfactory, and ecological properties of the mushrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "mush_df = pd.read_csv('/Users/Shared/mushrooms.csv')\n",
    "mush_df2 = pd.get_dummies(mush_df)\n",
    "\n",
    "X_mush = mush_df2.iloc[:,2:]\n",
    "y_mush = mush_df2.iloc[:,1]\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_mush, y_mush, random_state=0)\n",
    "\n",
    "# For performance reasons I will create a smaller version of the\n",
    "# entire mushroom dataset.  For simplicity I'll just re-use\n",
    "# the 25% test split created above as the representative subset.\n",
    "#\n",
    "\n",
    "X_subset = X_test2\n",
    "y_subset = y_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a Decision Tree Classifier to classify the mushrooms as poisonous or not. Then determine the 5 most important features found by the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['odor_n', 'stalk-root_c', 'stalk-root_r', 'spore-print-color_r', 'odor_l']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "    \n",
    "clf = DecisionTreeClassifier(random_state = 0).fit(X_train2, y_train2)\n",
    "features = clf.feature_importances_\n",
    "num_features = 5\n",
    "idx = features.argsort()[-num_features:]\n",
    "feature_names = X_train2.columns[idx].tolist()\n",
    "feature_names.reverse()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used the validation_curve function in sklearn.model_selection to determine training and test scores for a Support Vector Classifier (SVC) with varying parameter values and a radial basis kernel. I used a subset of the original mushroom datase for performance reasons. \n",
    "\n",
    "So the first step is to create an SVC object with default parameters (i.e. kernel='rbf', C=1) and random_state=0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "gamma_range = np.logspace(-4,1,6)\n",
    "clf = SVC(kernel = 'rbf', C = 1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this classifier, and the dataset in X_subset, y_subset, I explored the effect of gamma on classifier accuracy by using the validation_curve function to find the training and test scores for 6 values of gamma from 0.0001 to 10 (i.e. np.logspace(-4,1,6)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.58936484, 0.55686854, 0.55317578],\n",
       "        [0.93205318, 0.9239291 , 0.93722304],\n",
       "        [0.99113737, 0.99039882, 0.99039882],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [1.        , 1.        , 1.        ]]),\n",
       " array([[0.58345643, 0.56277696, 0.55539143],\n",
       "        [0.91580502, 0.94977843, 0.92466765],\n",
       "        [0.98966027, 0.99113737, 0.98818316],\n",
       "        [1.        , 1.        , 1.        ],\n",
       "        [0.98818316, 0.9985229 , 0.99704579],\n",
       "        [0.52141802, 0.52289513, 0.52289513]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_validation, test_validation = validation_curve(clf, X_subset, y_subset, scoring = 'accuracy', param_name = 'gamma', param_range = gamma_range, cv = 3)\n",
    "(train_validation, test_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, I used accuracy as the scoring metric and found the mean score across the three models for each level of gamma for both arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.56646972, 0.93106844, 0.990645  , 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([0.56720827, 0.9300837 , 0.98966027, 1.        , 0.99458395,\n",
       "        0.52240276]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_scores = np.mean(train_validation, axis = 1)\n",
    "test_scores = np.mean(test_validation, axis = 1)\n",
    "(training_scores, test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I determined which gamma value corresponds to a model that is underfitting (and has the worst training set accuracy), a model that is overfitting (and has the worst test set accuracy), and a model with good generalization performance (high accuracy on both training and test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, 10.0, 0.1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_range = np.logspace(-4,1,6)\n",
    "underfit = training_scores.argmin()\n",
    "overfit = (training_scores - test_scores).argmax()\n",
    "good = (training_scores + test_scores).argmax()\n",
    "(gamma_range[underfit], gamma_range[overfit], gamma_range[good])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
